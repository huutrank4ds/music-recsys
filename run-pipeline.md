---
description: Ch·∫°y pipeline ho√†n ch·ªânh t·ª´ ƒë·∫ßu ƒë·∫øn cu·ªëi (Updated Schema)
---
# üéµ Music Recommendation System - Pipeline (Updated)

H∆∞·ªõng d·∫´n ch·∫°y to√†n b·ªô h·ªá th·ªëng x·ª≠ l√Ω d·ªØ li·ªáu, hu·∫•n luy·ªán m√¥ h√¨nh v√† ki·ªÉm th·ª≠.
**L∆∞u √Ω:** Codebase ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t ƒë·ªÉ s·ª≠ d·ª•ng Schema chu·∫©n (`track_name`, `artist_name`, `plays_` as String, `duration` as String).

## üöÄ QUICK START (Start Infrastructure)

### B∆Ø·ªöC 0: Kh·ªüi ƒë·ªông Docker
```bash
docker-compose up -d
# ƒê·ª£i 2-3 ph√∫t cho c√°c services (MongoDB, MinIO, Spark, Milvus, Kafka) kh·ªüi ƒë·ªông ho√†n t·∫•t
```

# ================================================================
# PHASE 1: DATA PIPELINE (ETL & MODELING)
# ================================================================

### B∆Ø·ªöC 1: C√†i ƒë·∫∑t Dependencies (Spark)
```bash
docker exec spark-master pip install python-dotenv sentence-transformers pymilvus tqdm aiohttp
```

### B∆Ø·ªöC 2: Download Data (~5 ph√∫t)
```bash
docker exec -it spark-master python3 /opt/src/scripts/download_data.py
```

### B∆Ø·ªöC 3: Clean Data Format (~3 ph√∫t)
```bash
docker exec -it spark-master python3 /opt/src/scripts/fix_format.py
```

### B∆Ø·ªöC 4: Sort Data (~10 ph√∫t)
```bash
docker exec -it spark-master spark-submit /opt/src/scripts/preprocess_sort.py
```

### B∆Ø·ªöC 5: Streaming v√†o MinIO (2 TERMINALS, ~30 ph√∫t)

**Terminal 1 - Spark Streaming:**
```bash
docker exec -it spark-master spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.apache.hadoop:hadoop-aws:3.3.4 /opt/src/ingestion/stream_to_minio.py
```

**Terminal 2 - Producer:**
*(M·ªü terminal m·ªõi)*
```bash
docker exec -it spark-master python3 /opt/src/ingestion/producer.py --speed 20000
```
> ƒê·ª£i Producer ch·∫°y xong ‚Üí Ctrl+C c·∫£ 2 terminals.

### B∆Ø·ªöC 6: ETL Songs & Users (~10 ph√∫t)
*T·∫°o b·∫£ng `songs` v√† `users` trong MongoDB. Code ƒë√£ ƒë∆∞·ª£c update ƒë·ªÉ d√πng c·ªôt `track_name`, `artist_name` v√† √©p ki·ªÉu String.*
```bash
# ETL Songs
docker exec spark-master spark-submit --packages org.mongodb.spark:mongo-spark-connector_2.12:3.0.1 /opt/src/batch/etl_master_data.py

# ETL Users
docker exec spark-master spark-submit --packages org.mongodb.spark:mongo-spark-connector_2.12:3.0.1 /opt/src/batch/etl_users.py
```

### B∆Ø·ªöC 7: Train ALS Model (Collaborative Filtering) (~30 ph√∫t)
*T·∫°o vector s·ªü th√≠ch ng∆∞·ªùi d√πng. L∆∞u √Ω: S·ª≠ d·ª•ng RAM 2G cho Driver ƒë·ªÉ tr√°nh OOM.*
```bash
docker exec spark-master spark-submit --driver-memory 2g --packages org.apache.hadoop:hadoop-aws:3.3.4 /opt/src/modeling/train_als_model.py
```

### B∆Ø·ªöC 8: Enrich Lyrics (Fetch Data) (~10-15 gi·ªù)
*T·∫£i l·ªùi b√†i h√°t t·ª´ LRCLIB. Code ƒë√£ update ƒë·ªÉ t·ª± ƒë·ªông ƒëi·ªÅn `duration=300` v√† `release_date=null` n·∫øu thi·∫øu.*
```bash
docker exec -e MONGO_URI=mongodb://mongodb:27017 spark-master python3 -u /opt/src/scripts/fetch_lyrics_lrclib.py
```

### B∆Ø·ªöC 9: Clean Data (B·∫Øt bu·ªôc)
*X√≥a c√°c b√†i h√°t kh√¥ng t√¨m th·∫•y lyric ƒë·ªÉ chu·∫©n b·ªã t·∫°o Vector (tr√°nh l·ªói).*
```bash
docker exec -it -e MONGO_URI="mongodb://mongodb:27017" -e MILVUS_HOST="milvus-standalone" spark-master python3 /opt/src/scripts/clean_and_sync_data.py --yes
```

### B∆Ø·ªöC 10: Create Lyrics Embeddings (~1-2 gi·ªù)
*T·∫°o vector n·ªôi dung t·ª´ l·ªùi b√†i h√°t v√† ƒë·∫©y v√†o Milvus.*
```bash
# ƒê·∫£m b·∫£o Milvus ƒëang ch·∫°y
docker start milvus-standalone
timeout 30

docker exec -e MONGO_URI=mongodb://mongodb:27017 spark-master python3 -u /opt/src/modeling/create_lyrics_embeddings.py
```

# ================================================================
# PHASE 2: EXPORT & SERVING
# ================================================================

### B∆Ø·ªöC 11: Export Clean Data (Optional)
*Xu·∫•t d·ªØ li·ªáu `users` v√† `songs` ra file JSONL chu·∫©n ƒë·ªÉ ki·ªÉm tra ho·∫∑c backup.*
```bash
# Export Songs
docker exec spark-master python3 /opt/src/scripts/export_clean_dataset.py
docker cp spark-master:/opt/data/songs_clean.jsonl ./songs_clean.jsonl

# Export Users
docker exec mongodb mongoexport --db music_recsys --collection users --out /data/db/users.jsonl
docker cp mongodb:/data/db/users.jsonl ./users.jsonl
```

### B∆Ø·ªöC 12: Setup Backend & Test API
```bash
# Start Backend
docker-compose up -d backend

# Verify Logic
docker cp verify_hybrid_api.py music_backend:/app/verify_hybrid_api.py
docker exec music_backend python verify_hybrid_api.py
```

---

## üîß Mapping ƒê∆∞·ªùng D·∫´n
| Local | Container |
|:------|:----------|
| `data_pipeline/` | `/opt/src/` |
| `data/` | `/opt/data/` |
