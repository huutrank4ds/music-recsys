#!/bin/bash
# daily_workflow.sh
# ÄÆ°á»ng dáº«n log Ä‘á»ƒ theo dÃµi
LOG_FILE="/home/user/pipeline.log" 

log() {
    echo "$(date '+%Y-%m-%d %H:%M:%S') - $1" | tee -a $LOG_FILE
}

log "ğŸ”„ Báº®T Äáº¦U QUY TRÃŒNH TRAIN MODEL HÃ€NG NGÃ€Y"

# --- BÆ¯á»šC 1: Táº®T JOB MINIO ---
log "1. Äang táº¯t Job Stream to MinIO..."
# Lá»‡nh pkill -f tÃ¬m process theo tÃªn file python vÃ  kill nÃ³ bÃªn trong container
docker exec spark-master pkill -f "stream_to_minio.py"

# Äá»£i 10s Ä‘á»ƒ Spark dá»n dáº¹p vÃ  tráº£ Worker
sleep 15
log "   -> ÄÃ£ táº¯t Job MinIO. Worker 1 Ä‘Ã£ trá»‘ng."

# --- BÆ¯á»šC 2: CHáº Y TRAIN ALS ---
log "2. Äang cháº¡y Training ALS Model..."
# LÆ°u Ã½: KhÃ´ng dÃ¹ng -d (detach) á»Ÿ Ä‘Ã¢y. ChÃºng ta muá»‘n script Ä‘á»£i train xong má»›i Ä‘i tiáº¿p.
docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  --driver-memory 1g \
  --executor-memory 1g \
  --total-executor-cores 1 \
  /opt/src/training/train_als.py >> $LOG_FILE 2>&1

# Kiá»ƒm tra xem train cÃ³ thÃ nh cÃ´ng khÃ´ng
if [ $? -eq 0 ]; then
    log "   -> Training thÃ nh cÃ´ng!"
else
    log "âŒ Training tháº¥t báº¡i! Kiá»ƒm tra log."
    # DÃ¹ tháº¥t báº¡i váº«n pháº£i báº­t láº¡i MinIO Ä‘á»ƒ khÃ´ng máº¥t log
fi

# --- BÆ¯á»šC 3: Báº¬T Láº I JOB MINIO ---
log "3. Äang khá»Ÿi Ä‘á»™ng láº¡i Job Stream to MinIO..."
docker exec -d spark-master spark-submit \
  --master spark://spark-master:7077 \
  --driver-memory 512m \
  --executor-memory 800m \
  --total-executor-cores 1 \
  --conf "spark.kafka.consumer.cache.enabled=false" \
  /opt/src/jobs/stream_to_minio.py

log "âœ… QUY TRÃŒNH HOÃ€N Táº¤T. Há»‡ thá»‘ng Ä‘Ã£ trá»Ÿ láº¡i tráº¡ng thÃ¡i Streaming Full."