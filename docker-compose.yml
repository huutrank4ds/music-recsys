services:
  # -----------------------------------------------------------
  # 1. KAFKA (Apache Official - KRaft Mode)
  # -----------------------------------------------------------
  kafka:
    image: ${KAFKA_IMAGE}
    container_name: kafka
    hostname: kafka
    ports:
      - "${KAFKA_PORT_INTERNAL}:${KAFKA_PORT_INTERNAL}" # 9092
      - "${KAFKA_PORT_EXTERNAL}:${KAFKA_PORT_EXTERNAL}" # 9094
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      
      # C·∫•u h√¨nh Listener
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:${KAFKA_PORT_INTERNAL},CONTROLLER://0.0.0.0:${KAFKA_PORT_CONTROLLER},EXTERNAL://0.0.0.0:${KAFKA_PORT_EXTERNAL}
      
      # Quan tr·ªçng: Khai b√°o ƒë·ªãa ch·ªâ ƒë·ªÉ client k·∫øt n·ªëi
      # - PLAINTEXT: D√†nh cho Spark/Kafka-UI (g·ªçi t·ªõi kafka:9092)
      # - EXTERNAL: D√†nh cho Python Local (g·ªçi t·ªõi localhost:9094)
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:${KAFKA_PORT_INTERNAL},EXTERNAL://localhost:${KAFKA_PORT_EXTERNAL}
      
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:${KAFKA_PORT_CONTROLLER}
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT

      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_PARTITIONS: 4
      # Cho ph√©p nh·∫≠n tin nh·∫Øn l√™n t·ªõi 10MB (Bytes)
      KAFKA_MESSAGE_MAX_BYTES: 10485760 
      # Cho ph√©p replica fetch d·ªØ li·ªáu l·ªõn
      KAFKA_REPLICA_FETCH_MAX_BYTES: 10485760
    networks:
      - bigdata-net
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      # Ki·ªÉm tra s·ª©c kh·ªèe b·∫±ng c√°ch li·ªát k√™ topic (Thay v√¨ d√πng nc c√≥ th·ªÉ kh√¥ng c√≥ s·∫µn)
      test: ["CMD-SHELL", "/opt/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092 # K·∫øt n·ªëi n·ªôi b·ªô qua port 9092
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - bigdata-net

  # -----------------------------------------------------------
  # 2. SPARK MASTER
  # -----------------------------------------------------------
  spark-master:
    build:
      context: .
      dockerfile: ${SPARK_DOCKERFILE}
    image: ${SPARK_IMAGE_NAME}:${SPARK_VERSION}
    container_name: spark-master
    hostname: spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "${SPARK_MASTER_WEBUI_PORT}:8080"
      - "${SPARK_MASTER_RPC_PORT}:7077"
    environment:
      - SPARK_CONF_DIR=/opt/spark/conf
    volumes:
      - ./data:/opt/data
      - ./src:/opt/src
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - bigdata-net

  # -----------------------------------------------------------
  # 3. SPARK WORKER
  # -----------------------------------------------------------
  spark-worker:
    image: ${SPARK_IMAGE_NAME}:${SPARK_VERSION}
    container_name: spark-worker
    # K·∫øt n·ªëi t·ªõi spark-master qua hostname
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      - SPARK_WORKER_CORES=${SPARK_WORKER_CORES}
      - SPARK_WORKER_MEMORY=${SPARK_WORKER_MEMORY}
    depends_on:
      - spark-master
    volumes:
      - ./data:/opt/data
      - ./src:/opt/src
    networks:
      - bigdata-net

  # -----------------------------------------------------------
  # 4. MINIO (Data Lake)
  # -----------------------------------------------------------
  minio:
    image: ${MINIO_IMAGE}
    container_name: minio
    ports:
      - "${MINIO_API_PORT}:9000"
      - "${MINIO_CONSOLE_PORT}:9001"
    command: server /data --console-address ":9001"
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
    networks:
      - bigdata-net
    volumes:
      - minio_data:/data

  # -----------------------------------------------------------
  # 5. MONGODB (Database)
  # -----------------------------------------------------------
  mongodb:
    image: ${MONGO_IMAGE}
    container_name: mongodb
    ports:
      - "${MONGO_PORT}:27017"
    volumes:
      - mongo_data:/data/db
    networks:
      - bigdata-net
  
  # -----------------------------------------------------------
  # 6. Sync songs data to MongoDB
  # -----------------------------------------------------------
  etl-sync:
    image: ${SPARK_IMAGE_NAME}:${SPARK_VERSION}
    container_name: music-etl-sync
    user: root # ƒê·ªÉ c√≥ quy·ªÅn ƒë·ªçc file
    depends_on:
      - mongodb
      - spark-master
    volumes:
      - ./src:/opt/src
      - ./data:/opt/data
    command: >
      /bin/bash -c "
      pip install pymongo && 
      while true; do 
        echo 'üöÄ Starting Daily Sync Job...';
        
        # Ch·∫°y Python v√† ki·ªÉm tra k·∫øt qu·∫£
        if python3 -u /opt/src/2_processing/sync_master_data.py; then
          echo '‚úÖ Sync Success! Sleeping for 24 hours...';
          sleep 86400;  # 86400 gi√¢y = 24 gi·ªù
        else
          echo '‚ùå Sync Failed! Retrying in 10 seconds...';
          sleep 10;     # Ng·ªß 10s r·ªìi th·ª≠ l·∫°i ngay, tr√°nh spam log li√™n t·ª•c
        fi
        
      done"

networks:
  bigdata-net:
    name: ${NETWORK_NAME}
    driver: bridge

volumes:
  mongo_data:
  kafka_data:
  minio_data: