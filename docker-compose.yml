services:
  # -----------------------------------------------------------
  # 1. KAFKA (Apache Official - KRaft Mode)
  # -----------------------------------------------------------
  kafka:
    image: ${KAFKA_IMAGE}
    container_name: kafka
    hostname: kafka
    ports:
      - "${KAFKA_PORT_INTERNAL}:${KAFKA_PORT_INTERNAL}"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://:${KAFKA_PORT_INTERNAL},CONTROLLER://:${KAFKA_PORT_CONTROLLER}
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:${KAFKA_PORT_INTERNAL}
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:${KAFKA_PORT_CONTROLLER}
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_PARTITIONS: 1
    networks:
      - ${NETWORK_NAME}

  # -----------------------------------------------------------
  # 2. SPARK MASTER
  # -----------------------------------------------------------
  spark-master:
    build:
      context: .
      dockerfile: ${SPARK_DOCKERFILE}
    image: ${SPARK_IMAGE_NAME}:${SPARK_VERSION}
    container_name: spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "${SPARK_MASTER_WEBUI_PORT}:8080"
      - "${SPARK_MASTER_RPC_PORT}:7077"
    environment:
      - SPARK_CONF_DIR=/opt/spark/conf
    volumes:
      - ./data:/opt/data 
      - ./src:/opt/src
    networks:
      - ${NETWORK_NAME}

  # -----------------------------------------------------------
  # 3. SPARK WORKER
  # -----------------------------------------------------------
  spark-worker:
    image: ${SPARK_IMAGE_NAME}:${SPARK_VERSION}
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:${SPARK_MASTER_RPC_PORT}
    environment:
      - SPARK_WORKER_CORES=${SPARK_WORKER_CORES}
      - SPARK_WORKER_MEMORY=${SPARK_WORKER_MEMORY}
    depends_on:
      - spark-master
    volumes:
      - ./data:/opt/data
      - ./src:/opt/src
    networks:
      - ${NETWORK_NAME}
    deploy:
      replicas: 1

  # -----------------------------------------------------------
  # 4. MINIO (Data Lake)
  # -----------------------------------------------------------
  minio:
    image: ${MINIO_IMAGE}
    container_name: minio
    ports:
      - "${MINIO_API_PORT}:9000"
      - "${MINIO_CONSOLE_PORT}:9001"
    command: server /data --console-address ":9001"
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
    networks:
      - ${NETWORK_NAME}

  # -----------------------------------------------------------
  # 5. MONGODB (Database)
  # -----------------------------------------------------------
  mongodb:
    image: ${MONGO_IMAGE}
    container_name: mongodb
    ports:
      - "${MONGO_PORT}:27017"
    volumes:
      - mongo_data:/data/db
    networks:
      - ${NETWORK_NAME}

networks:
  bigdata-net:
    name: ${NETWORK_NAME}
    driver: bridge

volumes:
  mongo_data:
