# ğŸµ Music Recommendation System Design

**Project:** Big Data End-term Project  
**Architecture:** Lambda Architecture (Spark + Kafka + MongoDB + MinIO)

---

## ğŸ“– 1. System Overview (Tá»•ng quan há»‡ thá»‘ng)

Há»‡ thá»‘ng Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ cung cáº¥p tráº£i nghiá»‡m cÃ¡ nhÃ¢n hÃ³a cho ngÆ°á»i dÃ¹ng nghe nháº¡c, sá»­ dá»¥ng cÃ¡c cÃ´ng nghá»‡ Big Data Ä‘á»ƒ xá»­ lÃ½ dá»¯ liá»‡u lá»›n. Há»‡ thá»‘ng bao gá»“m hai tÃ­nh nÄƒng cá»‘t lÃµi:

1.  **Home Page Recommendations:** Gá»£i Ã½ danh sÃ¡ch bÃ i hÃ¡t phÃ¹ há»£p vá»›i "gu" cá»§a ngÆ°á»i dÃ¹ng má»—i khi há» truy cáº­p (Batch Processing).
2.  **Next Song Prediction:** Tá»± Ä‘á»™ng Ä‘á» xuáº¥t bÃ i hÃ¡t tiáº¿p theo dá»±a trÃªn bÃ i hÃ¡t Ä‘ang nghe (Real-time Context / Item-based Filtering).

---

## ğŸ“‚ 2. Project Structure (Cáº¥u trÃºc dá»± Ã¡n)

Tá»• chá»©c mÃ£ nguá»“n vÃ  dá»¯ liá»‡u Ä‘Æ°á»£c phÃ¢n chia rÃµ rÃ ng theo cÃ¡c táº§ng xá»­ lÃ½:

```text
music-recsys/
â”œâ”€â”€ docker-compose.yml           # Quáº£n lÃ½ háº¡ táº§ng (Spark, Kafka, Mongo, MinIO)
â”œâ”€â”€ .env
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_data.py
â”‚   â”œâ”€â”€ fix_format.py
â”‚   â””â”€â”€ preprocess_sort.py
â”œâ”€â”€ configs/                     # CÃ¡c file cáº¥u hÃ¬nh mÃ´i trÆ°á»ng
â”‚   â””â”€â”€ spark-defaults.conf
â”œâ”€â”€ data/                        # Dá»¯ liá»‡u (Mounted Volume - MÃ¡y Host)
â”‚   â”œâ”€â”€ raw/                     # Dá»¯ liá»‡u thÃ´ (Logs)
â”‚   â”œâ”€â”€ processed_sorted/        # Dá»¯ liá»‡u Parquet Ä‘Ã£ lÃ m sáº¡ch (Input cho Model)
â”‚   â”œâ”€â”€ songs_master_list/       # File JSON danh sÃ¡ch bÃ i hÃ¡t (Output bÆ°á»›c ETL)
â”‚   â””â”€â”€ checkpoints/             # Spark Streaming Checkpoints
â”œâ”€â”€ src/                         # MÃ£ nguá»“n chÃ­nh
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â”œâ”€â”€ app/                       <-- (Web App & API)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py                <-- (File cháº¡y chÃ­nh cá»§a Web)
â”‚   â”‚   â””â”€â”€ templates/
â”‚   â”‚       â””â”€â”€ index.html
â”‚   â””â”€â”€ pipelines/
â”‚       â”œâ”€â”€ ingestion/
â”‚       â”‚   â”œâ”€â”€ producer.py
â”‚       â”‚   â””â”€â”€ kafka_to_minio.py
â”‚       â””â”€â”€ batch/
â”‚           â””â”€â”€ sync_songs_master.py
```

## ğŸ—„ï¸ 3. Database Design (MongoDB Schema)

Há»‡ thá»‘ng sá»­ dá»¥ng **MongoDB** lÃ m **Serving Layer** Ä‘á»ƒ Ä‘áº£m báº£o Ä‘á»™ trá»… tháº¥p (<50ms) cho ngÆ°á»i dÃ¹ng cuá»‘i. Cáº§n táº¡o database tÃªn `music_recsys`.

### 3.1. Collection: `songs` (Master Data)
> **Má»¥c Ä‘Ã­ch:** LÆ°u trá»¯ thÃ´ng tin hiá»ƒn thá»‹ cá»§a bÃ i hÃ¡t (Metadata) nhÆ° tÃªn, ca sÄ©, áº£nh bÃ¬a.  
> **Nguá»“n:** TrÃ­ch xuáº¥t tá»« lá»‹ch sá»­ Log (ETL script).

| Field Name | Type | Description |
| :--- | :--- | :--- |
| `_id` | String | **PK**. MusicBrainz Track ID (UUID) |
| `title` | String | TÃªn bÃ i hÃ¡t |
| `artist` | String | TÃªn nghá»‡ sÄ© |
| `track_index` | Long | MÃ£ sá»‘ nguyÃªn (Mapping vá»›i Spark Model) |
| `url` | String | ÄÆ°á»ng dáº«n file nháº¡c (MinIO URL - Optional) |

### 3.2. Collection: `user_recommendations` (Batch View)
> **Má»¥c Ä‘Ã­ch:** Phá»¥c vá»¥ tÃ­nh nÄƒng "Gá»£i Ã½ cho báº¡n" á»Ÿ trang chá»§.  
> **Nguá»“n:** Output tá»« thuáº­t toÃ¡n **ALS (Collaborative Filtering)** cá»§a Spark.

| Field Name | Type | Description |
| :--- | :--- | :--- |
| `_id` | String | **PK**. User ID |
| `recommendations` | Array | Danh sÃ¡ch Top-K bÃ i hÃ¡t gá»£i Ã½ |
| â†³ `song_id` | String | MusicBrainz Track ID |
| â†³ `score` | Double | Äiá»ƒm dá»± Ä‘oÃ¡n (Rating) |

### 3.3. Collection: `song_similarities` (Real-time Context)
> **Má»¥c Ä‘Ã­ch:** Phá»¥c vá»¥ tÃ­nh nÄƒng "PhÃ¡t tiáº¿p theo" (Next Song Prediction).  
> **Nguá»“n:** Output tá»« ma tráº­n Ä‘áº·c trÆ°ng **Item-Item Similarity**.

| Field Name | Type | Description |
| :--- | :--- | :--- |
| `_id` | String | **PK**. Track ID bÃ i Ä‘ang nghe (Source) |
| `similar_songs` | Array | Danh sÃ¡ch bÃ i hÃ¡t tÆ°Æ¡ng Ä‘á»“ng nháº¥t |
| â†³ `song_id` | String | Track ID bÃ i gá»£i Ã½ |
| â†³ `similarity` | Double | Äá»™ tÆ°Æ¡ng Ä‘á»“ng Cosine (0.0 - 1.0) |

---

## ğŸ”„ 4. Workflow (Quy trÃ¬nh váº­n hÃ nh)

Quy trÃ¬nh váº­n hÃ nh Ä‘Æ°á»£c chia thÃ nh 3 giai Ä‘oáº¡n hoáº¡t Ä‘á»™ng tuáº§n hoÃ n:

### ğŸ”¹ Phase 1: Ingestion & Storage (Real-time)
*Thu tháº­p hÃ nh vi ngÆ°á»i dÃ¹ng vÃ  lÆ°u trá»¯ lÃ¢u dÃ i.*

1.  User tÆ°Æ¡ng tÃ¡c trÃªn Web App (nghe, like, skip).
2.  Script `producer.py` Ä‘áº©y sá»± kiá»‡n vÃ o **Kafka** topic `music_log`.
3.  Script `stream_to_minio.py` (Spark Structured Streaming) Ä‘á»c tá»« Kafka vÃ  ghi xuá»‘ng **MinIO** dÆ°á»›i dáº¡ng file **Parquet** (Ä‘Æ°á»£c partition theo ngÃ y `date=YYYY-MM-DD`).

### ğŸ”¹ Phase 2: Training & Computation (Batch - Daily)
*Cáº­p nháº­t trÃ­ tuá»‡ cho AI Ä‘á»‹nh ká»³ (hÃ ng ngÃ y hoáº·c má»—i 4 giá»).*

1.  **ETL Step:** Cháº¡y `etl_master_data.py`.
    * QuÃ©t logs trong MinIO.
    * Lá»c danh sÃ¡ch bÃ i hÃ¡t duy nháº¥t $\rightarrow$ Update vÃ o MongoDB collection `songs`.
2.  **Training Step:** Cháº¡y `train_als_model.py`.
    * Load Parquet tá»« MinIO.
    * Train **ALS Model** (Alternating Least Squares).
    * **Task A:** Dá»± Ä‘oÃ¡n Top songs cho má»—i User $\rightarrow$ Ghi Ä‘Ã¨ MongoDB `user_recommendations`.
    * **Task B:** TÃ­nh toÃ¡n Item Similarity Matrix $\rightarrow$ Ghi Ä‘Ã¨ MongoDB `song_similarities`.

### ğŸ”¹ Phase 3: Serving (Online)
*API Backend pháº£n há»“i Frontend dá»±a trÃªn dá»¯ liá»‡u Ä‘Ã£ tÃ­nh sáºµn.*

* **Scenario A: Home Page (Trang chá»§)**
    * Frontend gá»i API $\rightarrow$ Backend query `db.user_recommendations.find({"_id": user_id})`.
    * Backend láº¥y danh sÃ¡ch ID $\rightarrow$ Join vá»›i `db.songs` Ä‘á»ƒ láº¥y tÃªn bÃ i/nghá»‡ sÄ©.
    * Tráº£ vá» JSON cho Frontend hiá»ƒn thá»‹.
* **Scenario B: Next Song (BÃ i tiáº¿p theo)**
    * User Ä‘ang nghe bÃ i **X**.
    * Backend query `db.song_similarities.find({"_id": X})`.
    * Backend lá»c bá» cÃ¡c bÃ i User vá»«a nghe gáº§n Ä‘Ã¢y (trong Redis/Session) Ä‘á»ƒ trÃ¡nh láº·p.
    * Tráº£ vá» bÃ i hÃ¡t cÃ³ Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng cao nháº¥t.

---

## âœ… 5. Implementation Checklist

- [x] **Infrastructure:** Setup Docker Compose (Spark, Kafka, Mongo, MinIO).
- [x] **Producer:** Python script giáº£ láº­p dá»¯ liá»‡u vÃ o Kafka (Time Travel logic).
- [ ] **Streaming Consumer:** Spark Structured Streaming Ä‘á»c Kafka $\rightarrow$ Ghi MinIO Parquet.
- [ ] **ETL Master Data:** Spark Batch trÃ­ch xuáº¥t bÃ i hÃ¡t tá»« Parquet $\rightarrow$ MongoDB `songs`.
- [ ] **AI Model:** Spark MLlib train ALS & Item Similarity $\rightarrow$ MongoDB `user_recommendations` & `song_similarities`.
- [ ] **Backend API:** Python/NodeJS API query MongoDB phá»¥c vá»¥ Frontend.
