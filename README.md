
# ğŸµ Real-time Music Recommendation System

> Há»‡ thá»‘ng gá»£i Ã½ Ã¢m nháº¡c thá»i gian thá»±c sá»­ dá»¥ng kiáº¿n trÃºc **Lambda Architecture**, káº¿t há»£p sá»©c máº¡nh cá»§a **Collaborative Filtering (ALS)**, **Content-Based Filtering (BERT)** vÃ  **Session-based Recommendation**.

![Apache Spark](https://img.shields.io/badge/Apache%20Spark-FDEE21?style=for-the-badge&logo=apachespark&logoColor=black)
![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-000?style=for-the-badge&logo=apachekafka)
![MongoDB](https://img.shields.io/badge/MongoDB-4EA94B?style=for-the-badge&logo=mongodb&logoColor=white)
![Milvus](https://img.shields.io/badge/Milvus-00A1EA?style=for-the-badge&logo=milvus&logoColor=white)
![Redis](https://img.shields.io/badge/Redis-DC382D?style=for-the-badge&logo=redis&logoColor=white)
![React](https://img.shields.io/badge/React-20232A?style=for-the-badge&logo=react&logoColor=61DAFB)

---

## ğŸ“– System Overview (Tá»•ng quan há»‡ thá»‘ng)

Há»‡ thá»‘ng Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ cung cáº¥p tráº£i nghiá»‡m cÃ¡ nhÃ¢n hÃ³a cho ngÆ°á»i dÃ¹ng nghe nháº¡c, sá»­ dá»¥ng cÃ¡c cÃ´ng nghá»‡ Big Data Ä‘á»ƒ xá»­ lÃ½ dá»¯ liá»‡u lá»›n. Há»‡ thá»‘ng bao gá»“m hai tÃ­nh nÄƒng cá»‘t lÃµi:

1. **Home Page Recommendations:** Gá»£i Ã½ danh sÃ¡ch bÃ i hÃ¡t phÃ¹ há»£p vá»›i "gu" cá»§a ngÆ°á»i dÃ¹ng má»—i khi há» truy cáº­p (Batch Processing).
2. **Next Song Prediction:** Tá»± Ä‘á»™ng Ä‘á» xuáº¥t bÃ i hÃ¡t tiáº¿p theo dá»±a trÃªn bÃ i hÃ¡t Ä‘ang nghe (Real-time Context / Item-based Filtering).

---

## ğŸ“‚ Project Structure (Cáº¥u trÃºc dá»± Ã¡n)

Tá»• chá»©c mÃ£ nguá»“n vÃ  dá»¯ liá»‡u Ä‘Æ°á»£c phÃ¢n chia rÃµ rÃ ng theo cÃ¡c táº§ng xá»­ lÃ½:

```text
music-recsys/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api.Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ config.py ---> Cáº¥u hÃ¬nh sá»­ dá»¥ng bÃªn trong backend.
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â””â”€â”€ simulate_traffic.py ---> Code táº¡o giáº£ láº­p hÃ nh vi ngÆ°á»i dÃ¹ng.
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ main.py
â”‚       â”œâ”€â”€ api/
â”‚       â”‚   â”œâ”€â”€ recommendation_api.py
â”‚       â”‚   â”œâ”€â”€ search_api.py
â”‚       â”‚   â”œâ”€â”€ user_api.py
â”‚       â”‚   â””â”€â”€ logging_api.py
â”‚       â”œâ”€â”€ core/
â”‚       â”‚   â”œâ”€â”€ kafka_client.py
â”‚       â”‚   â””â”€â”€ database.py
â”‚       â””â”€â”€ services/
â”‚           â”œâ”€â”€ logging_service_be.py
â”‚           â”œâ”€â”€ user_service_be.py
â”‚           â”œâ”€â”€ search_service_be.py
â”‚           â””â”€â”€ recommendation_service_be.py
â”œâ”€â”€ common/
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”œâ”€â”€ log_schemas.py
â”‚   â”‚   â”œâ”€â”€ spark_schemas.py
â”‚   â”‚   â””â”€â”€ milvus_schemas.py
â”‚   â””â”€â”€ logger.py ---> Phá»¥ trÃ¡ch in log
â”œâ”€â”€ data/                       
â”‚   â”œâ”€â”€ raw/ ---> Dá»¯ liá»‡u thÃ´ (Logs)
â”‚   â”œâ”€â”€ processed_sorted/ ---> Dá»¯ liá»‡u Parquet Ä‘Ã£ lÃ m sáº¡ch (Input cho Model).
â”‚   â”œâ”€â”€ songs_master_data/ ---> Dá»¯ liá»‡u bÃ i hÃ¡t.
â”‚   â”œâ”€â”€ songs_master_data/ ---> Dá»¯ liá»‡u ngÆ°á»i dÃ¹ng.
â”‚   â”œâ”€â”€ simulation_logs/ ---> Chá»©a dá»¯ liá»‡u giáº£ láº­p hÃ nh vi ngÆ°á»i dÃ¹ng cuá»‘i dÃ¹ng.
â”‚   â”œâ”€â”€ lyrics_data/ ---> Chá»©a dá»¯ liá»‡u lá»i bÃ i hÃ¡t vÃ  dá»¯ liá»‡u vector nhÃºng lá»i bÃ i hÃ¡t.
â”‚   â””â”€â”€ checkpoints/ ---> Sá»­ dá»¥ng lÆ°u checkpoint Spark streaming (tÃ¹y chá»n).
â””â”€â”€ data_pipeline/                    
    â”œâ”€â”€ config.py
    â”œâ”€â”€ spark.Dockerfile
    â”œâ”€â”€ utils.py
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ batch/            
    â”‚   â”œâ”€â”€ resync_plays_7d.py --> Äá»“ng bá»™ lÆ°á»£t nghe trong 7 ngÃ y gáº§n nháº¥t trong dá»¯ liá»‡u bÃ i hÃ¡t tá»« log lÆ°u trong Minio.
    â”‚   â”œâ”€â”€ import_embedding_lyrics_collection.py ---> Nháº­p collection chá»©a vector nhÃºng lá»i bÃ i hÃ¡t vÃ o Milvus.
    â”‚   â”œâ”€â”€ import_users_master_data.py ---> Nháº­p dá»¯ liá»‡u ngÆ°á»i dÃ¹ng vÃ o MongoDB.
    â”‚   â””â”€â”€ import_songs_master_data.py ---> Nháº­p dá»¯ liá»‡u bÃ i hÃ¡t vÃ o MongoDB.
    â”œâ”€â”€ ingestion/
    â”‚   â”œâ”€â”€ incremental_update_listen_count.py ---> Äá»c Minio, cáº­p nháº­t lÆ°á»£t nghe bÃ i hÃ¡t má»—i 15 phÃºt.
    â”‚   â””â”€â”€ stream_to_minio.py ---> Spark streaming Ä‘á»c dá»¯ liá»‡u tá»« Kafka lÆ°u vÃ o Minio.
    â”œâ”€â”€ modeling/
    â”‚   â”œâ”€â”€ create_lyrics_embeddings.py ---> Láº¥y vector nhÃºng lá»i bÃ i hÃ¡t ghi collection vÃ o Milvus.
    â”‚   â””â”€â”€ train_als_batch.py ---> Huáº¥n luyá»‡n mÃ´ hÃ¬nh ALS cáº­p nháº­t vector ngÆ°á»i dÃ¹ng vÃ  vector bÃ i hÃ¡t.
    â”œâ”€â”€ orchestration/
    â”‚   â””â”€â”€ manager.py ---> Quáº£n lÃ½ cÃ¡c job spark, lÃªn lá»‹ch Ä‘á»“ng bá»™ dá»¯ liá»‡u vÃ  huáº¥n luyá»‡n ALS.
    â””â”€â”€ scripts/ ---> CÃ¡c scripts xá»­ lÃ½ dataset log hÃ nh vi láº¥y tá»« hugging face.
        â”œâ”€â”€ download_data.py
        â”œâ”€â”€ preprocess_sort.py
        â”œâ”€â”€ fix_format.py
        â”œâ”€â”€ ...
        â””â”€â”€ fetch_lyrics_lrclib.py
```

## ğŸ—„ï¸ Database Schema Design

Há»‡ thá»‘ng sá»­ dá»¥ng mÃ´ hÃ¬nh lÆ°u trá»¯ lai (Polyglot Persistence): **MongoDB** cho dá»¯ liá»‡u Ä‘á»‹nh danh/metadata, **Milvus** cho dá»¯ liá»‡u Vector Ä‘áº·c trÆ°ng, vÃ  **Redis** cho dá»¯ liá»‡u phiÃªn lÃ m viá»‡c (Session).

### Phase 0. MinIO (Data Lake - Raw Logs)
> LÆ°u trá»¯ nháº­t kÃ½ hÃ nh vi ngÆ°á»i dÃ¹ng (User Logs) dÆ°á»›i dáº¡ng **Parquet**, phÃ¢n vÃ¹ng theo ngÃ y.

* **Bucket:** `datalake`
* **Path:** `raw/logs/date=YYYY-MM-DD/part-*.parquet`

| Field | Type | Description |
| :--- | :--- | :--- |
| `user_id` | String | KhÃ³a ngoáº¡i tham chiáº¿u `users`. |
| `track_id` | String | KhÃ³a ngoáº¡i tham chiáº¿u `songs`. |
| `timestamp` | Long | Epoch Milliseconds. |
| `action` | String | `listen`, `skip`, `complete`. |
| `duration` | Integer | Thá»i gian Ä‘Ã£ nghe (giÃ¢y). |
| `total_duration` | Integer | Tá»•ng thá»i lÆ°á»£ng bÃ i hÃ¡t (giÃ¢y). |
| `source` | String | `simulation` hoáº·c `real_user`. |

### Phase 1. MongoDB (Metadata & User Profile)

#### Collection: `songs`
> LÆ°u trá»¯ thÃ´ng tin hiá»ƒn thá»‹ (Metadata).

| Field | Type | Description |
| :--- | :--- | :--- |
| `_id` | String | **PK**. Track ID (UUID). |
| `track_name` | String | TÃªn bÃ i hÃ¡t. |
| `artist_id` | String | ID nghá»‡ sÄ© |
| `artist_name` | String | TÃªn nghá»‡ sÄ©. |
| `image_url` | String | áº¢nh bÃ¬a bÃ i hÃ¡t. |
| `url` | String | ÄÆ°á»ng dáº«n bÃ i hÃ¡t. |
| `duration` | Double | Thá»i lÆ°á»£ng bÃ i hÃ¡t. |
| `plays_7d` | Int | LÆ°á»£t nghe trong 7 ngÃ y gáº§n nháº¥t (Trending). |
| `plays_cumulative` | Long | Tá»•ng lÆ°á»£t nghe tÃ­ch lÅ©y. |
| `lrclib_plain_lyrics`| String | Lá»i bÃ i hÃ¡t (Raw text). |
| `lrclib_synced_lyrics` | String | Lá»i bÃ i hÃ¡t cÃ³ thá»i gian. |
| `release_date` | Date | NgÃ y update. |

#### Collection: `users`
> LÆ°u trá»¯ vector sá»Ÿ thÃ­ch dÃ i háº¡n (Long-term profile).

| Field | Type | Description |
| :--- | :--- | :--- |
| `_id` | String | **PK**. User ID. |
| `username` | String | TÃªn hiá»ƒn thá»‹. |
| `latent_vector` | Array `<Float>` | Vector ALS `[0.1, -0.5, ...]` (64 dims). |
| `signup_date` | Date | NgÃ y Ä‘Äƒng kÃ­. |
| `image_url` | String | áº¢nh Ä‘áº¡i diá»‡n. |

### Phase 2. Milvus (Vector Database)

#### Collection 1: `music_collection` (Collaborative Filtering)
> LÆ°u trá»¯ vector Ä‘áº·c trÆ°ng bÃ i hÃ¡t tá»« mÃ´ hÃ¬nh ALS.
* **Metric Type:** `IP` (Inner Product).
* **Dim:** 64 (latent factors).

#### Collection 2: `lyrics_embeddings` (Content-Based Filtering)
> LÆ°u trá»¯ vector Ä‘áº·c trÆ°ng lá»i bÃ i hÃ¡t tá»« mÃ´ hÃ¬nh BERT.
* **Metric Type:** `IP` (Cosine Similarity).
* **Dim:** 384 (all-MiniLM-L6-v2).

---

## ğŸ”„ Operational Workflow

Há»‡ thá»‘ng hoáº¡t Ä‘á»™ng theo luá»“ng khÃ©p kÃ­n tá»« thu tháº­p dá»¯ liá»‡u (Streaming) Ä‘áº¿n huáº¥n luyá»‡n (Batch) vÃ  phá»¥c vá»¥ (Serving).

[Image of System Architecture Diagram]


### ğŸ”¹ Phase 1: Ingestion & Real-time Processing
1.  **Event Capture:** Frontend gá»i API gá»­i log hÃ nh vi (`listen`, `skip`, `complete`) vÃ o Backend.
2.  **Message Queue:** Backend Ä‘áº©y log vÃ o Kafka topic `music_log`.
3.  **Data Lake Sink:** Spark Streaming Ä‘á»c dá»¯ liá»‡u tá»« Kafka vÃ  ghi xuá»‘ng **MinIO** (Data Lake) dÆ°á»›i Ä‘á»‹nh dáº¡ng Parquet.
4.  **Near Real-time Stats:** Job Spark cháº¡y Ä‘á»‹nh ká»³ má»—i 5 phÃºt, cáº­p nháº­t tá»•ng lÆ°á»£t nghe vÃ  lÆ°á»£t nghe trong 7 ngÃ y cho bÃ i hÃ¡t trong MongoDB.

### ğŸ”¹ Phase 2: Batch Processing & Enrichment
1.  **Weekly Trending (Nightly):** Job Spark cháº¡y má»—i Ä‘Ãªm, tÃ­nh toÃ¡n tá»•ng lÆ°á»£t nghe trong 7 ngÃ y gáº§n nháº¥t (`plays_7d`) cáº­p nháº­t vÃ o MongoDB Ä‘á»ƒ phá»¥c vá»¥ BXH Trending.
2.  **Content Embedding (One-time):**
    * Sá»­ dá»¥ng mÃ´ hÃ¬nh BERT (`sentence-transformers`) trÃ­ch xuáº¥t vector tá»« lá»i bÃ i hÃ¡t.
    * LÆ°u vÃ o Milvus (`lyrics_embeddings`) phá»¥c vá»¥ Content-based Filtering.

### ğŸ”¹ Phase 3: Model Training (Collaborative Filtering)
1.  **Training:** Job Spark cháº¡y hÃ ng Ä‘Ãªm Ä‘á»c lá»‹ch sá»­ tá»« MinIO, huáº¥n luyá»‡n mÃ´ hÃ¬nh ALS (Alternating Least Squares).
2.  **Vector Sync:**
    * **User Vectors:** LÆ°u vÃ o MongoDB (`users`).
    * **Item Vectors:** LÆ°u vÃ o Milvus (`music_collection`).

### ğŸ”¹ Phase 4: Serving & Recommendation Logic
Há»‡ thá»‘ng sá»­ dá»¥ng cÆ¡ cháº¿ **Session-based Hybrid Recommendation**.

#### ğŸ§  1. Session Vector Calculation
Há»‡ thá»‘ng tá»•ng há»£p sá»Ÿ thÃ­ch dÃ i háº¡n (Long-term) vÃ  ngáº¯n háº¡n (Short-term) theo cÃ´ng thá»©c:

$$
\vec{V}_{session} = 0.7 \times \vec{V}_{long\_term} + 0.3 \times \vec{V}_{short\_term}
$$

* **Long-term ($\vec{V}_{long\_term}$):** Vector ALS cá»§a User tá»« MongoDB (cáº­p nháº­t hÃ ng Ä‘Ãªm).
* **Short-term ($\vec{V}_{short\_term}$):** Vector phiÃªn lÃ m viá»‡c hiá»‡n táº¡i, lÆ°u trong **Redis**. Cáº­p nháº­t real-time theo cÃ´ng thá»©c **Exponential Moving Average**:
    $$
    \vec{V}_{short\_new} = 0.5 \times \vec{V}_{short\_old} + 0.5 \times \vec{V}_{current\_song}
    $$

#### ğŸ  2. Scenario A: Home Page (Discovery)
* **Logic:** Collaborative Filtering thuáº§n tÃºy.
* **Process:** DÃ¹ng $\vec{V}_{session}$ tÃ¬m kiáº¿m cÃ¡c bÃ i hÃ¡t tÆ°Æ¡ng Ä‘á»“ng nháº¥t trong **Milvus** (`music_collection`).

#### â­ï¸ 3. Scenario B: Next Song (Hybrid Filtering)
* **Logic:** Káº¿t há»£p hÃ nh vi ngÆ°á»i dÃ¹ng (ALS) vÃ  ná»™i dung bÃ i hÃ¡t (Lyrics).
* **Scoring Formula:** Äiá»ƒm sá»‘ cuá»‘i cÃ¹ng Ä‘Æ°á»£c tá»•ng há»£p tá»« hai nguá»“n Ä‘Ã£ Ä‘Æ°á»£c chuáº©n hÃ³a (Normalized):
    $$
    Score_{final} = 0.6 \times Norm(Score_{ALS}) + 0.4 \times Norm(Score_{Content})
    $$
* **Process:**
    1.  TÃ¬m Candidate tá»« Milvus (ALS Vector).
    2.  TÃ¬m Candidate tá»« Milvus (Lyrics Vector).
    3.  Trá»™n káº¿t quáº£ vÃ  xáº¿p háº¡ng láº¡i (Re-ranking).

---

## ğŸ§¬ System Architecture Diagram

```mermaid
graph TD
    %% --- ACTORS ---
    UI["Frontend UI"]
    Sim["Simulated Logs"]
    
    %% --- REAL-TIME SESSION LOOP (Serving Layer) ---
    subgraph "Real-time Session Logic"
        API["Backend API"]
        Redis[("Redis: Session Cache")]
        
        UI <-->|"1. Req/Res (Get Recs)"| API
        API <-->|"2. Get/Update v_short"| Redis
        
        %% Note: Logic API cache v_long tá»« Mongo vÃ o Redis
        noteRedis[/"API Ä‘á»c v_long tá»« Mongo<br/>lÆ°u vÃ o Redis"/]
        Redis -.- noteRedis
    end

    %% --- INGESTION PIPELINE (Speed Layer Input) ---
    subgraph "Data Ingestion"
        direction TB
        UI -->|"Log Event"| API
        Sim -->|"Log Event"| Kafka["Kafka Topic: music_log"]
        API -->|"Push Log"| Kafka
        Kafka -->|"Spark Streaming"| MinIO[("MinIO: Data Lake")]
    end

    %% --- BATCH PROCESSING & STORAGE (Batch Layer) ---
    subgraph "Batch Processing"
        direction TB
        MinIO -->|"Read delta (15m)"| Spark15m["Spark Job: Update Stats"]
        MinIO -->|"Read 90 days"| SparkALS["Spark Job: ALS Training"]
        MinIO -->|"Read delta (Nightly)"| SparkNight["Spark Job: Nightly Stats"]
        
        %% Database Updates
        Spark15m -->|"Update songs col"| MongoDB[("MongoDB")]
        SparkNight -->|"Resync songs col"| MongoDB
        SparkALS -->|"Update users col"| MongoDB
        SparkALS -->|"Write music col"| Milvus[("Milvus")]
        
        %% Content Enrichment
        MongoDB -->|"Read songs col"| BERT["BERT Inference"]
        BERT -->|"Write lyrics emb"| Milvus
    end

    %% --- SERVING CONNECTIONS (Retrieval) ---
    %% API orchestration: API lÃ  trung tÃ¢m káº¿t ná»‘i DB
    API -.->|"Read Metadata/User Profile"| MongoDB
    API -.->|"Vector Search (Candidates)"| Milvus
```

## âœ… Implementation Checklist (Tiáº¿n Ä‘á»™ thá»±c hiá»‡n)

DÆ°á»›i Ä‘Ã¢y lÃ  danh sÃ¡ch cÃ¡c háº¡ng má»¥c cÃ´ng viá»‡c cáº§n hoÃ n thÃ nh Ä‘á»ƒ váº­n hÃ nh há»‡ thá»‘ng.

### 1. ğŸ—ï¸ Infrastructure (Háº¡ táº§ng)
> Má»¥c tiÃªu: Dá»±ng mÃ´i trÆ°á»ng container á»•n Ä‘á»‹nh cho Big Data & AI.

- [X] **Docker Compose Setup**
  - [X] Cáº¥u hÃ¬nh Apache Spark (Master & Worker).
  - [X] Cáº¥u hÃ¬nh Kafka KRAFT (Message Broker).
  - [X] Cáº¥u hÃ¬nh MinIO (S3 Compatible Data Lake).
  - [X] Cáº¥u hÃ¬nh MongoDB (NoSQL Database).
  - [X] Cáº¥u hÃ¬nh Milvus (Vector Database) & Attu Dashboard.
  - [X] Cáº¥u hÃ¬nh Redis (In-memory Cache cho Session).
- [X] **Networking:** Äáº£m báº£o cÃ¡c container thÃ´ng nhau (Bridge Network).
- [X] **Volume Persistence:** Mount volume cho DB Ä‘á»ƒ trÃ¡nh máº¥t dá»¯ liá»‡u khi restart.

### 2. ğŸ“¥ Data Ingestion (Thu tháº­p dá»¯ liá»‡u)
> Má»¥c tiÃªu: ÄÆ°a dá»¯ liá»‡u hÃ nh vi ngÆ°á»i dÃ¹ng vÃ o Data Lake.

- [X] **Fake Data Producer**
  - [X] Script Python giáº£ láº­p hÃ nh vi nghe nháº¡c.
  - [X] Äáº©y message vÃ o Kafka topic `music_log`.
- [X] **Streaming Pipeline**
  - [X] Spark Structured Streaming Ä‘á»c tá»« Kafka.
  - [X] Sink dá»¯ liá»‡u xuá»‘ng MinIO dÆ°á»›i dáº¡ng file `.parquet`.
  - [X] Partition dá»¯ liá»‡u theo ngÃ y (`date=YYYY-MM-DD`).

### 3. ğŸ§¹ ETL & Master Data (LÃ m sáº¡ch & Metadata)
> Má»¥c tiÃªu: Äá»“ng bá»™ danh sÃ¡ch bÃ i hÃ¡t chuáº©n vÃ  xá»­ lÃ½ ná»™i dung.

- [X] **Song Metadata Sync**
  - [X] Import dá»¯ liá»‡u bÃ i hÃ¡t/nghá»‡ sÄ© vÃ o MongoDB collection `songs`.
  - [X] ÄÃ¡nh index tá»‘i Æ°u cho viá»‡c truy váº¥n.
- [X] **Content Enrichment**
  - [X] Fetch lá»i bÃ i hÃ¡t (Lyrics) tá»« API.
  - [X] **Embedding:** DÃ¹ng BERT trÃ­ch xuáº¥t vector tá»« Lyrics.
  - [X] **Indexing:** LÆ°u vector vÃ o Milvus (`lyrics_embeddings`).

### 4. ğŸ§  AI & Model Training (Batch Processing)
> Má»¥c tiÃªu: Há»c thÃ³i quen ngÆ°á»i dÃ¹ng & Sinh Vector Ä‘áº·c trÆ°ng.

- [X] **Training Job (Nightly)**
  - [X] Load dá»¯ liá»‡u Parquet 90 ngÃ y gáº§n nháº¥t tá»« MinIO.
  - [X] Huáº¥n luyá»‡n mÃ´ hÃ¬nh **ALS (Alternating Least Squares)**.
  - [X] **Export Users:** LÆ°u vector ngÆ°á»i dÃ¹ng vÃ o MongoDB (`users`).
  - [X] **Export Items:** LÆ°u vector bÃ i hÃ¡t vÃ o Milvus (`music_collection`).
- [X] **Statistics Job**
  - [X] TÃ­nh toÃ¡n lÆ°á»£t nghe 7 ngÃ y gáº§n nháº¥t (`plays_7d`) Ä‘á»ƒ cáº­p nháº­t Trending.

### 5. ğŸ”Œ Backend API (Serving Layer)
> Má»¥c tiÃªu: API phá»¥c vá»¥ Frontend & TÃ­nh toÃ¡n Recommendation Logic.

- [X] **Core Logic**
  - [X] Káº¿t ná»‘i Ä‘a luá»“ng: Mongo, Milvus, Redis.
  - [X] **Session Vector:** TÃ­nh toÃ¡n `0.7 * Long-term + 0.3 * Short-term`.
  - [X] **Short-term Memory:** Cáº­p nháº­t Redis vector theo thá»i gian thá»±c (EMA).
  - [X] **Hybrid Scoring:** `0.6 * ALS + 0.4 * Content`.
- [X] **API Endpoints**
  - [X] `GET /api/v1/recs/{user_id}`: Gá»£i Ã½ trang chá»§.
  - [X] `GET /api/v1/recs/{user_id}/{current_song_id}`: Gá»£i Ã½ bÃ i tiáº¿p theo (Context-aware).
  - [X] `POST /api/v1/logs/event`: Nháº­n log tá»« Client.

### 6. ğŸ’» Frontend (Web App)
> Má»¥c tiÃªu: Giao diá»‡n ngÆ°á»i dÃ¹ng cuá»‘i.

- [X] **Home Page:** Hiá»ƒn thá»‹ danh sÃ¡ch gá»£i Ã½ cÃ¡ nhÃ¢n hÃ³a & Trending.
- [X] **Music Player:**
  - [X] PhÃ¡t nháº¡c trá»±c tiáº¿p tá»« MongoDB.
  - [X] Tracking thá»i gian nghe thá»±c táº¿.
  - [X] Gá»­i log update session khi nghe > 30s.
- [X] **Smart Queue:** Tá»± Ä‘á»™ng fetch bÃ i hÃ¡t tiáº¿p theo tá»« API khi playlist sáº¯p háº¿t.

---

## ğŸš€ HÆ°á»›ng dáº«n cháº¡y (Quick Start)

### 1. Khá»Ÿi Ä‘á»™ng Háº¡ táº§ng
Cháº¡y toÃ n bá»™ há»‡ thá»‘ng báº±ng Docker Compose:

```bash
docker compose up -d
```

### 2. Náº¡p dá»¯ liá»‡u master vÃ  dá»¯ liá»‡u vector tá»« lá»i bÃ i hÃ¡t(láº§n Ä‘áº§u cháº¡y)
TrÆ°á»›c khi há»‡ thá»‘ng cÃ³ thá»ƒ hoáº¡t Ä‘á»™ng, cáº§n náº¡p dá»¯ liá»‡u bÃ i hÃ¡t (Songs) vÃ  ngÆ°á»i dÃ¹ng (Users) vÃ o MongoDB.

```bash
docker compose run --rm job-sync-master
``` 

VÃ o giao diá»‡n Minio á»Ÿ Ä‘á»‹a chá»‰ http://localhost:9001, nháº­p username vÃ  password báº±ng giÃ¡ trá»‹ Ä‘Ã£ set trong tá»‡p mÃ´i trÆ°á»ng .env. VÃ o bucket liÃªn káº¿t Milvus vÃ  import file `embeddings_lyrics.parquet` tá»« thÆ° má»¥c `data/lyrics_data` vÃ o. Sau Ä‘Ã³ cháº¡y lá»‡nh Ä‘á»ƒ náº¡p dá»¯ liá»‡u vector lá»i bÃ i hÃ¡t vÃ o
`lyrics_embeddings` collection trong Milvus.
```bash
docker exec -it spark-master python3 /opt/src/batch/import_embedding_lyrics_collection.py
```

### 3. Kiá»ƒm tra tráº¡ng thÃ¡i & Truy cáº­p Dashboard
Äáº£m báº£o cÃ¡c container Ä‘á»u á»Ÿ tráº¡ng thÃ¡i `Healthy` hoáº·c `Up` báº±ng lá»‡nh `docker ps`. Sau Ä‘Ã³ truy cáº­p cÃ¡c trang quáº£n trá»‹:

- Frontend Web App: http://localhost:5173
- Backend API Docs: http://localhost:8000/docs
- MinIO Console: http://localhost:9001
- Spark Master UI: http://localhost:9090
- Kafka UI: http://localhost:8080

### 4. Cháº¡y giáº£ láº­p dá»¯ liá»‡u (Simulate Traffic)
Cháº¡y script giáº£ láº­p Ä‘á»ƒ sinh log hÃ nh vi (listen, skip, complete) Ä‘áº©y vÃ o Kafka. Log giáº£ láº­p nÃ y chá»‰ cÃ³ hÃ nh vi complete, cÃ³ thá»ƒ sá»­ dá»¥ng Ä‘á»ƒ huáº¥n luyá»‡n ALS.
```bash
docker exec -it music-backend python3 /app/scripts/simulate_traffic.py --speed 200
```

### 5. Dá»«ng há»‡ thá»‘ng
Äá»ƒ táº¯t cÃ¡c container nhÆ°ng váº«n giá»¯ láº¡i dá»¯ liá»‡u (trong Volumes):
```bash
docker compose down
```
