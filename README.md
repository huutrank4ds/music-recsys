# ğŸµ Music Recommendation System Design

**Project:** Big Data End-term Project  
**Architecture:** Lambda Architecture (Spark + Kafka + MongoDB + MinIO)

---

## ğŸ“– 1. System Overview (Tá»•ng quan há»‡ thá»‘ng)

Há»‡ thá»‘ng Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ cung cáº¥p tráº£i nghiá»‡m cÃ¡ nhÃ¢n hÃ³a cho ngÆ°á»i dÃ¹ng nghe nháº¡c, sá»­ dá»¥ng cÃ¡c cÃ´ng nghá»‡ Big Data Ä‘á»ƒ xá»­ lÃ½ dá»¯ liá»‡u lá»›n. Há»‡ thá»‘ng bao gá»“m hai tÃ­nh nÄƒng cá»‘t lÃµi:

1.  **Home Page Recommendations:** Gá»£i Ã½ danh sÃ¡ch bÃ i hÃ¡t phÃ¹ há»£p vá»›i "gu" cá»§a ngÆ°á»i dÃ¹ng má»—i khi há» truy cáº­p (Batch Processing).
2.  **Next Song Prediction:** Tá»± Ä‘á»™ng Ä‘á» xuáº¥t bÃ i hÃ¡t tiáº¿p theo dá»±a trÃªn bÃ i hÃ¡t Ä‘ang nghe (Real-time Context / Item-based Filtering).

---

## ğŸ“‚ 2. Project Structure (Cáº¥u trÃºc dá»± Ã¡n)

Tá»• chá»©c mÃ£ nguá»“n vÃ  dá»¯ liá»‡u Ä‘Æ°á»£c phÃ¢n chia rÃµ rÃ ng theo cÃ¡c táº§ng xá»­ lÃ½:

```text
music-recsys/
â”œâ”€â”€ docker-compose.yml           # Quáº£n lÃ½ háº¡ táº§ng (Spark, Kafka, Mongo, MinIO)
â”œâ”€â”€ configs/                     # CÃ¡c file cáº¥u hÃ¬nh mÃ´i trÆ°á»ng
â”‚   â””â”€â”€ spark-defaults.conf
â”œâ”€â”€ data/                        # Dá»¯ liá»‡u (Mounted Volume - MÃ¡y Host)
â”‚   â”œâ”€â”€ raw/                     # Dá»¯ liá»‡u thÃ´ (Logs)
â”‚   â”œâ”€â”€ processed_sorted/        # Dá»¯ liá»‡u Parquet Ä‘Ã£ lÃ m sáº¡ch (Input cho Model)
â”‚   â”œâ”€â”€ songs_master_list/       # File JSON danh sÃ¡ch bÃ i hÃ¡t (Output bÆ°á»›c ETL)
â”‚   â””â”€â”€ checkpoints/             # Spark Streaming Checkpoints
â”œâ”€â”€ src/                         # MÃ£ nguá»“n chÃ­nh
â”‚   â”œâ”€â”€ 1_ingestion/             # Táº§ng thu tháº­p dá»¯ liá»‡u
â”‚   â”‚   â”œâ”€â”€ producer.py          # Giáº£ láº­p hÃ nh vi User -> Kafka (Time Travel logic)
â”‚   â”‚   â””â”€â”€ stream_to_minio.py   # Spark Streaming: Äá»c Kafka -> Ghi MinIO
â”‚   â”œâ”€â”€ 2_processing/            # Táº§ng xá»­ lÃ½ Batch & AI
â”‚   â”‚   â”œâ”€â”€ etl_master_data.py   # TrÃ­ch xuáº¥t danh sÃ¡ch bÃ i hÃ¡t -> MongoDB
â”‚   â”‚   â””â”€â”€ train_als_model.py   # Huáº¥n luyá»‡n ALS -> MongoDB (UserRecs & ItemSims)
â”‚   â””â”€â”€ 3_serving/               # Táº§ng phá»¥c vá»¥ (Backend)
â”‚       â””â”€â”€ api_server.py        # API Query MongoDB tráº£ vá» Frontend
â””â”€â”€ notebooks/                   # Jupyter Notebook (DÃ¹ng Ä‘á»ƒ kiá»ƒm thá»­ nhanh)
```

## ğŸ—„ï¸ 3. Database Design (MongoDB Schema)

Há»‡ thá»‘ng sá»­ dá»¥ng **MongoDB** lÃ m **Serving Layer** Ä‘á»ƒ Ä‘áº£m báº£o Ä‘á»™ trá»… tháº¥p (<50ms) cho ngÆ°á»i dÃ¹ng cuá»‘i. Cáº§n táº¡o database tÃªn `music_recsys`.

### 3.1. Collection: `songs` (Master Data)
> **Má»¥c Ä‘Ã­ch:** LÆ°u trá»¯ thÃ´ng tin hiá»ƒn thá»‹ cá»§a bÃ i hÃ¡t (Metadata) nhÆ° tÃªn, ca sÄ©, áº£nh bÃ¬a.  
> **Nguá»“n:** TrÃ­ch xuáº¥t tá»« lá»‹ch sá»­ Log (ETL script).

| Field Name | Type | Description |
| :--- | :--- | :--- |
| `_id` | String | **PK**. MusicBrainz Track ID (UUID) |
| `title` | String | TÃªn bÃ i hÃ¡t |
| `artist` | String | TÃªn nghá»‡ sÄ© |
| `track_index` | Long | MÃ£ sá»‘ nguyÃªn (Mapping vá»›i Spark Model) |
| `url` | String | ÄÆ°á»ng dáº«n file nháº¡c (MinIO URL - Optional) |

### 3.2. Collection: `user_recommendations` (Batch View)
> **Má»¥c Ä‘Ã­ch:** Phá»¥c vá»¥ tÃ­nh nÄƒng "Gá»£i Ã½ cho báº¡n" á»Ÿ trang chá»§.  
> **Nguá»“n:** Output tá»« thuáº­t toÃ¡n **ALS (Collaborative Filtering)** cá»§a Spark.

| Field Name | Type | Description |
| :--- | :--- | :--- |
| `_id` | String | **PK**. User ID |
| `recommendations` | Array | Danh sÃ¡ch Top-K bÃ i hÃ¡t gá»£i Ã½ |
| â†³ `song_id` | String | MusicBrainz Track ID |
| â†³ `score` | Double | Äiá»ƒm dá»± Ä‘oÃ¡n (Rating) |

### 3.3. Collection: `song_similarities` (Real-time Context)
> **Má»¥c Ä‘Ã­ch:** Phá»¥c vá»¥ tÃ­nh nÄƒng "PhÃ¡t tiáº¿p theo" (Next Song Prediction).  
> **Nguá»“n:** Output tá»« ma tráº­n Ä‘áº·c trÆ°ng **Item-Item Similarity**.

| Field Name | Type | Description |
| :--- | :--- | :--- |
| `_id` | String | **PK**. Track ID bÃ i Ä‘ang nghe (Source) |
| `similar_songs` | Array | Danh sÃ¡ch bÃ i hÃ¡t tÆ°Æ¡ng Ä‘á»“ng nháº¥t |
| â†³ `song_id` | String | Track ID bÃ i gá»£i Ã½ |
| â†³ `similarity` | Double | Äá»™ tÆ°Æ¡ng Ä‘á»“ng Cosine (0.0 - 1.0) |

---

## ğŸ”„ 4. Workflow (Quy trÃ¬nh váº­n hÃ nh)

Quy trÃ¬nh váº­n hÃ nh Ä‘Æ°á»£c chia thÃ nh 3 giai Ä‘oáº¡n hoáº¡t Ä‘á»™ng tuáº§n hoÃ n:

### ğŸ”¹ Phase 1: Ingestion & Storage (Real-time)
*Thu tháº­p hÃ nh vi ngÆ°á»i dÃ¹ng vÃ  lÆ°u trá»¯ lÃ¢u dÃ i.*

1.  User tÆ°Æ¡ng tÃ¡c trÃªn Web App (nghe, like, skip).
2.  Script `producer.py` Ä‘áº©y sá»± kiá»‡n vÃ o **Kafka** topic `music_log`.
3.  Script `stream_to_minio.py` (Spark Structured Streaming) Ä‘á»c tá»« Kafka vÃ  ghi xuá»‘ng **MinIO** dÆ°á»›i dáº¡ng file **Parquet** (Ä‘Æ°á»£c partition theo ngÃ y `date=YYYY-MM-DD`).

### ğŸ”¹ Phase 2: Training & Computation (Batch - Daily)
*Cáº­p nháº­t trÃ­ tuá»‡ cho AI Ä‘á»‹nh ká»³ (hÃ ng ngÃ y hoáº·c má»—i 4 giá»).*

1.  **ETL Step:** Cháº¡y `etl_master_data.py`.
    * QuÃ©t logs trong MinIO.
    * Lá»c danh sÃ¡ch bÃ i hÃ¡t duy nháº¥t $\rightarrow$ Update vÃ o MongoDB collection `songs`.
2.  **Training Step:** Cháº¡y `train_als_model.py`.
    * Load Parquet tá»« MinIO.
    * Train **ALS Model** (Alternating Least Squares).
    * **Task A:** Dá»± Ä‘oÃ¡n Top songs cho má»—i User $\rightarrow$ Ghi Ä‘Ã¨ MongoDB `user_recommendations`.
    * **Task B:** TÃ­nh toÃ¡n Item Similarity Matrix $\rightarrow$ Ghi Ä‘Ã¨ MongoDB `song_similarities`.

### ğŸ”¹ Phase 3: Serving (Online)
*API Backend pháº£n há»“i Frontend dá»±a trÃªn dá»¯ liá»‡u Ä‘Ã£ tÃ­nh sáºµn.*

* **Scenario A: Home Page (Trang chá»§)**
    * Frontend gá»i API $\rightarrow$ Backend query `db.user_recommendations.find({"_id": user_id})`.
    * Backend láº¥y danh sÃ¡ch ID $\rightarrow$ Join vá»›i `db.songs` Ä‘á»ƒ láº¥y tÃªn bÃ i/nghá»‡ sÄ©.
    * Tráº£ vá» JSON cho Frontend hiá»ƒn thá»‹.
* **Scenario B: Next Song (BÃ i tiáº¿p theo)**
    * User Ä‘ang nghe bÃ i **X**.
    * Backend query `db.song_similarities.find({"_id": X})`.
    * Backend lá»c bá» cÃ¡c bÃ i User vá»«a nghe gáº§n Ä‘Ã¢y (trong Redis/Session) Ä‘á»ƒ trÃ¡nh láº·p.
    * Tráº£ vá» bÃ i hÃ¡t cÃ³ Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng cao nháº¥t.

---

## âœ… 5. Implementation Checklist

- [x] **Infrastructure:** Setup Docker Compose (Spark, Kafka, Mongo, MinIO, Milvus).
- [x] **Producer:** Python script giáº£ láº­p dá»¯ liá»‡u vÃ o Kafka (Time Travel logic).
- [x] **Streaming Consumer:** Spark Structured Streaming Ä‘á»c Kafka â†’ Ghi MinIO Parquet.
- [x] **ETL Master Data:** Spark Batch trÃ­ch xuáº¥t bÃ i hÃ¡t tá»« Parquet â†’ MongoDB `songs`.
- [x] **ETL Users:** Spark Batch trÃ­ch xuáº¥t users tá»« Parquet â†’ MongoDB `users`.
- [x] **AI Model:** Spark MLlib train ALS & Sync vectors:
  - User Factors â†’ MongoDB `users.latent_vector`
  - Item Factors â†’ Milvus `music_collection`
- [ ] **Backend API:** Python/NodeJS API query MongoDB + Milvus phá»¥c vá»¥ Frontend.

---

## ğŸ”¹ 6. Milvus Vector Database

### Collection: `music_collection`
> **Má»¥c Ä‘Ã­ch:** LÆ°u trá»¯ vector Ä‘áº·c trÆ°ng cá»§a bÃ i hÃ¡t Ä‘á»ƒ tÃ¬m kiáº¿m tÆ°Æ¡ng Ä‘á»“ng (Item-based).
> **Metric Type:** IP (Inner Product) - TÆ°Æ¡ng thÃ­ch vá»›i thuáº­t toÃ¡n ALS.
> **Index Type:** IVF_FLAT

| Field Name | Type | Description |
| :--- | :--- | :--- |
| `id` | VARCHAR(100) | **PK**. Track ID (Map vá»›i MongoDB) |
| `embedding` | FLOAT_VECTOR(64) | Item Factors tá»« Spark ALS |

### How it works:
1. **Training:** Spark ALS train model â†’ Extract itemFactors (64-dim vectors).
2. **Indexing:** Insert vectors vÃ o Milvus vá»›i IVF_FLAT index.
3. **Search:** Query user vector (tá»« MongoDB) â†’ Milvus tráº£ vá» Top-K similar songs.

---

## ğŸ”„ 7. Phase 2: Batch Training (Nightly Job)

### Chiáº¿n lÆ°á»£c Sliding Window
DÃ¹ng dá»¯ liá»‡u **90 ngÃ y gáº§n nháº¥t** Ä‘á»ƒ train model.

### Workflow:
```bash
# BÆ°á»›c 1: ETL Master Data (songs)
docker exec spark-master spark-submit /opt/src/processing/etl_master_data.py

# BÆ°á»›c 2: ETL Users 
docker exec spark-master spark-submit /opt/src/processing/etl_users.py

# BÆ°á»›c 3: Train ALS & Sync Vectors
docker exec spark-master spark-submit /opt/src/processing/train_als_model.py
```

### Output:
- **MongoDB `users`**: Má»—i user cÃ³ `latent_vector` (64-dim).
- **Milvus `music_collection`**: Má»—i bÃ i hÃ¡t cÃ³ `embedding` (64-dim).

---

## ğŸ“¦ 8. Docker Services

| Service | Port | Purpose |
| :--- | :--- | :--- |
| Kafka | 9092, 9094 | Message Queue |
| Kafka UI | 8080 | Kafka Dashboard |
| Spark Master | 9090 | Spark Web UI |
| MinIO | 9000, 9001 | Object Storage (Data Lake) |
| MongoDB | 27017 | Metadata & User Profiles |
| Milvus | 19530 | Vector Database |
