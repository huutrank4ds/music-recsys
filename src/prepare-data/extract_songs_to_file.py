from pathlib import Path
from pyspark.sql import SparkSession
from pyspark.sql.functions import col
from pyspark.sql.types import StructType, StructField, StringType, LongType

# ================= 1. HÃ€M TIá»†N ÃCH =================
def get_valid_parquet_files(data_dir_path):
    """
    QuÃ©t file parquet sá»­ dá»¥ng pathlib
    Input: data_dir_path (Path object hoáº·c string)
    Output: List cÃ¡c Ä‘Æ°á»ng dáº«n Ä‘á»‹nh dáº¡ng URI (file://...)
    """
    # Chuyá»ƒn Ä‘á»•i sang Path object náº¿u Ä‘áº§u vÃ o lÃ  string
    data_path = Path(data_dir_path)
    
    print(f"ğŸ” Äang quÃ©t file trong: {data_path}")
    
    if not data_path.exists():
        print(f"âŒ ThÆ° má»¥c khÃ´ng tá»“n táº¡i: {data_path}")
        return []

    # Sá»­ dá»¥ng pathlib Ä‘á»ƒ glob vÃ  filter
    # f.name: tÃªn file (vd: part-0000.parquet)
    # f.resolve(): Ä‘Æ°á»ng dáº«n tuyá»‡t Ä‘á»‘i (vd: /opt/data/...)
    valid_files = [
        f"file://{f.resolve()}" 
        for f in data_path.glob("*.parquet") 
        if not f.name.startswith(('.', '_'))
    ]
    
    # Sáº¯p xáº¿p Ä‘á»ƒ Ä‘áº£m báº£o thá»© tá»± Ä‘á»c nháº¥t quÃ¡n
    valid_files.sort()
    return valid_files

# ================= 2. HÃ€M CHÃNH =================
def main():
    # Sá»­ dá»¥ng Path object cho Ä‘Æ°á»ng dáº«n Ä‘áº§u vÃ o
    BASE_DIR = Path("/opt/data/processed_sorted")
    
    # ÄÆ°á»ng dáº«n Ä‘áº§u ra Spark váº«n nÃªn Ä‘á»ƒ dáº¡ng string URI chuáº©n
    OUTPUT_DIR = "file:///opt/data/songs_master_list"

    input_files = get_valid_parquet_files(BASE_DIR)
    
    if not input_files:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y file!")
        return

    print(f"âœ… TÃ¬m tháº¥y {len(input_files)} file sáº¡ch.")

    print("\nğŸš€ Khá»Ÿi táº¡o Spark Session...")
    spark = SparkSession.builder \
        .appName("ExtractSongsFixedType") \
        .config("spark.driver.memory", "3g") \
        .getOrCreate()

    # Schema giá»¯ nguyÃªn
    song_schema = StructType([
        StructField("musicbrainz_track_id", StringType(), True),
        StructField("track_name", StringType(), True),
        StructField("musicbrainz_artist_id", StringType(), True),
        StructField("artist_name", StringType(), True),
        StructField("track_index", LongType(), True),
        StructField("artist_index", LongType(), True)
    ])

    try:
        print("ğŸ“– Äang Ä‘á»c dá»¯ liá»‡u...")
        # Spark nháº­n list cÃ¡c Ä‘Æ°á»ng dáº«n string
        raw_df = spark.read.schema(song_schema).parquet(*input_files)
        
        print("ğŸ”„ Äang xá»­ lÃ½ ETL...")
        songs_df = raw_df.select(
            col("musicbrainz_track_id").alias("id"),
            col("track_name"),
            col("musicbrainz_artist_id"),
            col("artist_name"),
            col("track_index"),
            col("artist_index")
        ).dropDuplicates(["id"])

        count = songs_df.count()
        print(f"ğŸµ TÃ¬m tháº¥y tá»•ng cá»™ng: {count} bÃ i hÃ¡t duy nháº¥t.")

        print(f"ğŸ’¾ Äang ghi file JSON vÃ o: {OUTPUT_DIR}")
        
        # Ghi song song (KhÃ´ng dÃ¹ng coalesce Ä‘á»ƒ trÃ¡nh OOM)
        songs_df.write \
            .mode("overwrite") \
            .json(OUTPUT_DIR)

        print("âœ… THÃ€NH CÃ”NG! BÃ¢y giá» báº¡n hÃ£y kiá»ƒm tra thÆ° má»¥c data.")

    except Exception as e:
        print(f"ğŸ’¥ VáºªN CÃ’N Lá»–I: {e}")
    finally:
        spark.stop()

if __name__ == "__main__":
    main()