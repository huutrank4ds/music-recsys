"""
TURBO PRODUCER - Gá»­i dá»¯ liá»‡u vá»›i tá»‘c Ä‘á»™ tá»‘i Ä‘a (khÃ´ng giáº£ láº­p thá»i gian thá»±c)
"""
import json
import socket
from datetime import datetime
import pyarrow.parquet as pq
from pathlib import Path
from confluent_kafka import Producer
from confluent_kafka.admin import AdminClient, NewTopic

# ================= Cáº¤U HÃŒNH KAFKA (ÄÃƒ Tá»I Æ¯U) =================
CONF = {
    'bootstrap.servers': 'kafka:9092',
    'client.id': socket.gethostname(),
    'acks': '1',                    # Chá»‰ cáº§n 1 broker xÃ¡c nháº­n
    'linger.ms': 50,                # Chá» 50ms Ä‘á»ƒ gom batch (tÄƒng tá»« 5)
    'batch.size': 131072,           # Batch 128KB (tÄƒng tá»« 16KB)
    'compression.type': 'lz4',      # LZ4 nhanh hÆ¡n gzip
    'queue.buffering.max.messages': 100000,  # Buffer lá»›n hÆ¡n
    'queue.buffering.max.kbytes': 1048576,   # 1GB buffer
}

TOPIC = "music_log"
DATA_DIR = Path('/opt/data/processed_sorted')
TIMESTAMP_COL = 'timestamp'
NUM_PARTITIONS = 4
REPLICATION_FACTOR = 1

BATCH_SIZE = 10000  # TÄƒng batch size Ä‘á»c file (tá»« 2000 lÃªn 10000)
FLUSH_EVERY = 50000  # Flush sau má»—i 50k messages

# ================= HÃ€M QUáº¢N LÃ TOPIC =================
def ensure_topic_exists():
    print(f"ðŸ”§ Äang kiá»ƒm tra Topic '{TOPIC}'...")
    admin_client = AdminClient({'bootstrap.servers': CONF['bootstrap.servers']})
    cluster_metadata = admin_client.list_topics(timeout=10)
    
    if TOPIC in cluster_metadata.topics:
        print(f" Topic '{TOPIC}' Ä‘Ã£ tá»“n táº¡i.")
    else:
        print(f"Topic chÆ°a cÃ³. Äang táº¡o má»›i vá»›i {NUM_PARTITIONS} partitions...")
        new_topic = NewTopic(
            topic=TOPIC, 
            num_partitions=NUM_PARTITIONS, 
            replication_factor=REPLICATION_FACTOR
        )
        fs = admin_client.create_topics([new_topic])
        for topic, future in fs.items():
            try:
                future.result()
                print(f" ÄÃ£ táº¡o thÃ nh cÃ´ng topic: {topic}")
            except Exception as e:
                print(f" KhÃ´ng thá»ƒ táº¡o topic {topic}: {e}")

# ================= TURBO GENERATOR (KHÃ”NG CÃ“ DELAY) =================
def turbo_data_generator(data_dir):
    """Generator Ä‘á»c dá»¯ liá»‡u KHÃ”NG cÃ³ delay - tá»‘c Ä‘á»™ tá»‘i Ä‘a"""
    files = sorted([f for f in data_dir.glob("*.parquet") if f.is_file() and not f.name.startswith('.')])
    if not files:
        print("KhÃ´ng tÃ¬m tháº¥y file.")
        return

    print(f"ðŸš€ TURBO MODE: Äá»c {len(files)} files vá»›i tá»‘c Ä‘á»™ Tá»I ÄA!")
    
    for file_path in files:
        print(f"\nðŸ“– Äá»c file: {file_path.name}")
        parquet_file = pq.ParquetFile(file_path)

        for batch in parquet_file.iter_batches(batch_size=BATCH_SIZE):
            records = batch.to_pylist()
            for record in records:
                # Cáº­p nháº­t timestamp thÃ nh thá»i Ä‘iá»ƒm hiá»‡n táº¡i
                record[TIMESTAMP_COL] = datetime.now().isoformat()
                yield record

# ================= MAIN =================
def delivery_report(err, msg):
    if err is not None: 
        print(f'Lá»—i: {err}')

def run_producer():
    import time
    start_time = time.time()
    
    # 1. KIá»‚M TRA TOPIC
    ensure_topic_exists()
    
    # 2. KHá»žI Táº O PRODUCER
    print("ðŸ”Œ Khá»Ÿi táº¡o Producer TURBO...")
    producer = Producer(CONF)
    
    data_stream = turbo_data_generator(DATA_DIR)
    total_sent = 0

    try:
        for record in data_stream:
            msg_value = json.dumps(record, default=str).encode('utf-8')
            producer.produce(TOPIC, value=msg_value, callback=delivery_report)
            
            # Poll khÃ´ng Ä‘á»£i Ä‘á»ƒ tá»‘i Ä‘a throughput
            producer.poll(0)
            total_sent += 1
            
            # Flush Ä‘á»‹nh ká»³ Ä‘á»ƒ trÃ¡nh buffer Ä‘áº§y
            if total_sent % FLUSH_EVERY == 0:
                producer.flush(timeout=5)
                elapsed = time.time() - start_time
                rate = total_sent / elapsed
                print(f" Sent: {total_sent:,} | Rate: {rate:,.0f} msg/s | Elapsed: {elapsed:.1f}s")
        
        producer.flush(30)
        elapsed = time.time() - start_time
        rate = total_sent / elapsed if elapsed > 0 else 0
        print(f"\n DONE: {total_sent:,} messages in {elapsed:.1f}s ({rate:,.0f} msg/s)")
        
    except KeyboardInterrupt:
        print("\n Stopped.")
    except Exception as e:
        print(f"\n Error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    run_producer()
